{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Benvenuto","text":"<p>\ud83d\ude80 Scopri le funzionalit\u00e0 di Service Mesh e gRPC con questa demo!</p> <p>Questa demo ti guider\u00e0 attraverso le principali caratteristiche della service mesh e del protocollo gRPC , offrendoti un'anteprima pratica di ci\u00f2 che puoi fare.</p>"},{"location":"#cosa-troverai-in-questa-demo","title":"Cosa troverai in questa demo?","text":"<ul> <li>\u2705 Introduzione al progetto: una panoramica sulle funzionalit\u00e0 principali.</li> <li>\ud83d\udee0 Installazione e configurazione: istruzioni per iniziare rapidamente.</li> <li>\ud83d\udcd6 Guida all'uso: esempi pratici e suggerimenti utili.</li> <li>\ud83d\udca1 FAQ e supporto: risposte alle domande pi\u00f9 comuni.</li> </ul> <p>Buon proseguimento! \ud83d\ude80</p>"},{"location":"argo_rollout_istio/","title":"Argo Rollouts &amp; Istio Service Mesh","text":"<p>Il supporto di Istio all'interno di Argo Rollouts utilizza le risorse Gateway e VirtualService per gesire il routing del traffico.</p> <ul> <li> <p>Gateway: puoi utilizzare un Gateway per gestire il traffico in entrata e in uscita per la tua mesh. Il gateway \u00e8 il punto di ingresso della Service Mesh e gestisce le richieste di traffico inviate a un'applicazione.</p> </li> <li> <p>VirtualService: definisce le regole di routing del traffico e la percentuale di traffico che va ai servizi sottostanti, come i servizi stable e canary</p> </li> </ul> <p>Quando si utilizza la Service Mesh, Argo Rollouts modifica automaticamente la risorsa VirtualService per controllare la percentuale di traffico suddiviso tra le versioni stable e canary. Nel diagramma seguente, il 20 % del traffico viene inviato alla versione canary dell'applicazione dopo la prima promotion e quindi l'80% viene inviato alla versione stabile del servizio.</p> <p></p>"},{"location":"argo_rollout_istio/#1-requisiti","title":"1. Requisiti","text":"<ul> <li>Red Hat Openshift GitOps</li> <li>Argo Rollouts</li> <li>Argo Rollouts CLI</li> <li>Openshift Service Mesh</li> </ul>"},{"location":"argo_rollout_istio/#2-definizione-servicemeshcontrolplane","title":"2. Definizione ServiceMeshControlPlane","text":"<pre><code>apiVersion: maistra.io/v2\nkind: ServiceMeshControlPlane\nmetadata:\n  name: basic\n  namespace: istio-system\nspec:\n  addons:\n    grafana:\n      enabled: true\n    jaeger:\n      install:\n        storage:\n          type: Memory\n    kiali:\n      enabled: true\n    prometheus:\n      enabled: true\n  gateways:\n    openshiftRoute:\n      enabled: true\n  mode: MultiTenant\n  policy:\n    type: Istiod\n  profiles:\n    - default\n  telemetry:\n    type: Istiod\n  tracing:\n    sampling: 10000\n    type: Jaeger\n  version: v2.6\n</code></pre>"},{"location":"argo_rollout_istio/#3-definizione-servicemeshmemberrole","title":"3. Definizione ServiceMeshMemberRole","text":"<pre><code>apiVersion: maistra.io/v1\nkind: ServiceMeshMemberRoll\nmetadata:\n  name: default\n  namespace: istio-system\nspec:\n  members:\n    - istio-rollouts\n</code></pre>"},{"location":"argo_rollout_istio/#31-injection-automatica-dei-sidecar","title":"3.1 Injection automatica dei sidecar","text":"<p>E' possibile sfruttare l'injection automatica dei sidecar configurando una label direttamente sul namespace eseguendo il comando:</p> <pre><code>oc label namespace istio-rollouts istio-injection=enabled\n</code></pre>"},{"location":"argo_rollout_istio/#4-crezione-risorse","title":"4. Crezione risorse","text":""},{"location":"argo_rollout_istio/#41-gateway","title":"4.1 Gateway","text":"<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: rollouts-demo-gateway \nspec:\n  selector:\n    istio: ingressgateway \n  servers:\n  - port:\n      number: 80\n      name: http\n      protocol: HTTP\n    hosts:\n    - \"*\"\n</code></pre>"},{"location":"argo_rollout_istio/#42-servizi","title":"4.2 Servizi","text":"<p><pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: rollouts-demo-stable\nspec:\n  ports: \n  - port: 80\n    targetPort: http\n    protocol: TCP\n    name: http\n  selector: \n    app: rollouts-demo\n</code></pre> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: rollouts-demo-canary\nspec:\n  ports: \n  - port: 80\n    targetPort: http\n    protocol: TCP\n    name: http\n  selector: \n    app: rollouts-demo\n</code></pre></p>"},{"location":"argo_rollout_istio/#43-virtualservice","title":"4.3 VirtualService","text":"<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: rollouts-demo-vsvc\nspec:\n  gateways:\n  - rollouts-demo-gateway \n  hosts:\n  - rollouts-demo-vsvc.local\n  http:\n  - name: primary\n    route:\n    - destination:\n        host: rollouts-demo-stable \n        port:\n          number: 15372 \n      weight: 100\n    - destination:\n        host: rollouts-demo-canary \n        port:\n          number: 15372\n      weight: 0\n  tls: \n  - match:\n    - port: 3000\n      sniHosts:\n      - rollouts-demo-vsvc.local\n    route:\n    - destination:\n        host: rollouts-demo-stable\n      weight: 100\n    - destination:\n        host: rollouts-demo-canary\n      weight: 0\n</code></pre>"},{"location":"argo_rollout_istio/#44-rollout","title":"4.4 Rollout","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: rollouts-demo\nspec:\n  replicas: 5\n  strategy:\n    canary:\n      canaryService: rollouts-demo-canary \n      stableService: rollouts-demo-stable \n      trafficRouting:\n        istio:\n          virtualServices:\n          - name: rollouts-demo-vsvc\n            routes:\n            - primary\n      steps: \n      - setWeight: 20\n      - pause: {}\n      - setWeight: 40\n      - pause: {}\n      - setWeight: 60\n      - pause: {duration: 30}\n      - setWeight: 80\n      - pause: {duration: 60}\n  revisionHistoryLimit: 2\n  selector: \n    matchLabels:\n      app: rollouts-demo\n  template:\n    metadata:\n      labels:\n        app: rollouts-demo\n        istio-injection: enabled\n    spec:\n      containers:\n      - name: rollouts-demo\n        image: argoproj/rollouts-demo:blue\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            memory: 32Mi\n            cpu: 5m\n</code></pre> <p>Verificare che la service mesh indirizzi il 100% del traffico verso la versione stabile dell'applicazione.</p> <pre><code>oc argo rollouts get rollout rollouts-demo --watch -n istio-rollouts\n</code></pre>"},{"location":"argo_rollout_istio/#5-simulare-nuova-versione-canary","title":"5. Simulare nuova versione canary","text":"<p>Simula la nuova versione canary dell'applicazione modificando l'immagine del container distribuita durante il rollout</p> <pre><code>oc argo rollouts set image rollouts-demo rollouts-demo=argoproj/rollouts-demo:yellow -n istio-rollouts\n</code></pre> <p>Di conseguenza, l'immagine del container distribuita durante il rollout viene modificata e il rollout avvia una nuova distribuzione canary</p>"},{"location":"argo_rollout_istio/#6-promote","title":"6. Promote","text":"<pre><code>oc argo rollouts promote rollouts-demo -n istio-rollouts\n</code></pre> <p>Il 60% del traffico viene indirizzato al servizio stable e il 40% al servizio canary. Il deployment viene quindi messo in pausa a tempo indeterminato finch\u00e9 non lo si promuove manualmente al livello successivo.</p>"},{"location":"argo_rollout_istio/#61-step-finale-100","title":"6.1 Step finale (100%)","text":"<p>Aumentare il peso del traffico nella versione canary al 100% ed eliminare il traffico nella precedente versione stabile dell'applicazione eseguendo il seguente comando:</p> <pre><code>oc argo rollouts promote rollouts-demo -n istio-rollouts\n</code></pre> <p>Dopo il completamento con successo, il peso sul servizio stable \u00e8 del 100% e 0% sul servizio canary.</p>"},{"location":"argocdrollout/","title":"Argo Rollouts","text":""},{"location":"argocdrollout/#1-overview","title":"1. Overview","text":"<p>Argo Rollouts \u00e8 un controller Kubernetes e un set di CRD che forniscono funzionalit\u00e0 di distribuzione avanzate come blue-green, canary, canary analysis, sperimentazione e funzionalit\u00e0 di distribuzione progressiva su Kubernetes</p> <p>Argo Rollouts si integra con gli Ingress Controllers e le service mesh, sfruttando le loro capacit\u00e0 di modellazione del traffico per spostare gradualmente il traffico alla nuova versione durante un aggiornamento. Inoltre, Rollouts pu\u00f2 interrogare e interpretare le metriche di vari provider per verificare i KPI e guidare la promozione o il rollback automatizzati durante un aggiornamento.</p> <p></p> <p>Il Deployment di Kubernetes supporta la strategia di \"RollingUpdate\" che fornisce un set base di garanzie di sicurezza durante un aggiornamento (readiness probes). Tuttavia, la strategia di RollingUpdate presente alcune limitazioni:</p> <ul> <li>Pochi controlli sulla velocit\u00e0 del rollout</li> <li>Impossibilit\u00e0 di controllare il flusso di traffico verso la nuova versione</li> <li>Le readiness probes non sono adatte per controlli pi\u00f9 approfonditi, stress o una tantum</li> <li>Nessuna possibilit\u00e0 di interrogare metriche esterne per verificare un aggiornamento</li> <li>Pu\u00f2 interrompere la progressione, ma non \u00e8 in grado di annullare automaticamente l'aggiornamento</li> </ul> <p>Per questi motivi, in ambienti di produzione su larga scala, un RollingUpdate \u00e8 spesso considerato una procedura di aggiornamento troppo rischiosa poich\u00e9 non fornisce alcun controllo e rollback automatico in caso di guasti.</p> <p>Vantaggi di Argo Rollouts</p> <ul> <li>Funzionalit\u00e0 di distribuzione avanzate</li> <li>Ottimizzazione delle strategie di distribuzione avanzate esistenti come blue-green o canary</li> <li>Aggiornamenti senza tempi di inattivit\u00e0 per i Deployments</li> <li>Spostamento del traffico ponderato</li> <li>Possibilit\u00e0 di eseguire test senza che alcun nuovo traffico raggiunga l'ambiente di produzione</li> <li>Rollback e promozioni automatizzati</li> <li>Query metriche personalizzabili e analisi degli indicatori chiave delle prestazioni aziendali (KPI)</li> <li>Integrazione con controller di ingresso e Red Hat OpenShift Service Mesh per il routing avanzato del traffico</li> </ul>"},{"location":"argocdrollout/#2-installation","title":"2. Installation","text":""},{"location":"argocdrollout/#21-prerequisiti","title":"2.1 Prerequisiti","text":"<ul> <li>Red Hat Openshift GitOps (Operator)</li> <li>Argo Rollouts (Helm)</li> <li>Argo Rollouts CLI</li> </ul>"},{"location":"argocdrollout/#3-creazione-namespace","title":"3. Creazione namespace","text":"<p>Creiamo il progetto in cui desideriamo creare e configurare una risorsa personalizzata (CR) di Rollout.</p> <pre><code>oc new-project demo-rollout\n</code></pre>"},{"location":"argocdrollout/#4-crezione-risorsa-rollout","title":"4. Crezione risorsa Rollout","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: rollouts-demo\nspec:\n  replicas: 5\n  strategy:\n    canary: # La strategia di deployment che il rollout user\u00e0\n      steps: # Specifica gli step per il rollout. Questo esempio indirizza gradualmente il 20%, 40%, 60% e 80% del traffico alla versione canary\n      - setWeight: 20 \n      - pause: {} # Specificare al controller Argo Rollouts di sospendere indefinitamente finch\u00e9 non viene trovata una richiesta di promozione\n      - setWeight: 40\n      - pause: {duration: 45}  \n      - setWeight: 60\n      - pause: {duration: 20}\n      - setWeight: 80\n      - pause: {duration: 10}\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: rollouts-demo\n  template: \n    metadata:\n      labels:\n        app: rollouts-demo\n    spec:\n      containers:\n      - name: rollouts-demo\n        image: argoproj/rollouts-demo:blue\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            memory: 32Mi\n            cpu: 5m\n</code></pre>"},{"location":"argocdrollout/#5-creazione-dei-servizi-kubernetes-destinati-al-rollout-demo","title":"5. Creazione dei servizi Kubernetes destinati al rollout-demo","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: rollouts-demo\nspec:\n  ports: \n  - port: 80\n    targetPort: http\n    protocol: TCP\n    name: http\n\n  selector: \n    app: rollouts-demo\n</code></pre> <p>Si pu\u00f2 osservare l'andamento del rollout utilizzando questo comando:</p> <pre><code>oc argo rollouts get rollout rollouts-demo --watch -n demo-rollout\n</code></pre>"},{"location":"argocdrollout/#6-aggiornamento-del-rollout","title":"6. Aggiornamento del Rollout","text":"<p>Quando si aggiorna la risorsa personalizzata (CR) di Rollout con modifiche ai campi .spec.template.spec, ad esempio la versione dell'immagine del contenitore, vengono creati nuovi pod tramite ReplicaSet utilizzando la versione aggiornata dell'immagine del container.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: rollouts-demo\nspec:\n  replicas: 5\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20 \n      - pause: {}\n      - setWeight: 40\n      - pause: {duration: 45}  \n      - setWeight: 60\n      - pause: {duration: 20}\n      - setWeight: 80\n      - pause: {duration: 10}\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: rollouts-demo\n  template: \n    metadata:\n      labels:\n        app: rollouts-demo\n    spec:\n      containers:\n      - name: rollouts-demo\n        image: argoproj/rollouts-demo:yellow\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            memory: 32Mi\n            cpu: 5m\n</code></pre> <p>L'immagine del container distribuita durante il rollout viene modificata e il rollout avvia una nuova distribuzione canary.</p> <p>Osserva l'avanzamento del tuo rollout eseguendo il seguente comando:</p> <pre><code>oc argo rollouts get rollout rollouts-demo --watch -n demo-rollout\n</code></pre>"},{"location":"argocdrollout/#7-promuovere-il-rollout","title":"7. Promuovere il Rollout","text":"<p>Poich\u00e9 il rollout \u00e8 ora in pausa, in qualit\u00e0 di amministratore del cluster bisogna promuoverlo manualmente per consentirgli di procedere alla fase successiva.</p> <pre><code>oc argo rollouts promote rollouts-demo -n demo-rollout\n</code></pre> <p>Ci\u00f2 aumenta il peso del traffico al 40% nella versione canary. (come visto nella prima definizione del Rollout)</p> <p>Poich\u00e9 i restanti passaggi definiti nel Rollout hanno durate definite, ad esempio pausa: {duration: 45}, il controller Argo Rollouts attende tale durata e poi passa automaticamente al passaggio successivo.</p> <p>Una volta completati correttamente tutti i passaggi, il nuovo oggetto ReplicaSet viene contrassegnato come stabile.</p>"},{"location":"argocdrollout/#8-interruzione-manuale-del-rollout","title":"8. Interruzione manuale del rollout","text":"<p>Quando si usa un deployment canary, il rollout distribuisce una versione canary iniziale dell'applicazione. Dopo aver verificato la versione canary e averla promossa a stabile, la nuova versione stabile viene resa disponibile a tutti gli utenti.</p> <p>Tuttavia, a volte vengono scoperti bug, errori o problemi di distribuzione nella versione canary e potrebbe essere necessario annullare il rollout e ripristinare una versione stabile dell'applicazione.</p> <p>L'interruzione di un rollout elimina le risorse della nuova versione canary e ripristina la precedente versione stabile dell'applicazione. Di conseguenza, tutto il traffico che era indirizzato alla versione canary torna alla versione stabile.</p> <ul> <li>Aggiorniamo cos\u00ec l'immagine del container:</li> </ul> <pre><code>oc argo rollouts set image rollouts-demo rollouts-demo=argoproj/rollouts-demo:red -n demo-rollout\n</code></pre> <ul> <li>Verifichiamo che il rollout distribuisca la nuova versione canary e raggiunga lo stato di pausa</li> </ul> <pre><code>oc argo rollouts get rollout rollouts-demo --watch -n demo-rollout\n</code></pre> <ul> <li>Quindi interrompiamo l'aggiornamento del rollout eseguendo il comando:</li> </ul> <pre><code>oc argo rollouts abort rollouts-demo -n demo-rollout\n</code></pre> <p>Il controller Argo Rollouts elimina le risorse canary dell'applicazione e torna alla versione stabile. Possiamo verificarlo nuovamente eseguendo il comando:</p> <pre><code>oc argo rollouts get rollout rollouts-demo --watch -n demo-rollout\n</code></pre> <ul> <li>Aggiorniamo nuovamente l'immagine del container alla precedente versione stabile:</li> </ul> <pre><code>oc argo rollouts set image rollouts-demo rollouts-demo=argoproj/rollouts-demo:yellow -n demo-rollout\n</code></pre> <p>Il rollout salta i passaggi di analisi e promozione, torna alla versione stabile precedente (\"yellow\") e accelera la distribuzione del ReplicaSet stabile.</p> <p>Possiamo verificare che lo stato di rollout \u00e8 stato marcato come \"Healthy\" eseguendo nuovamente il comando:</p> <pre><code>oc argo rollouts get rollout rollouts-demo --watch -n demo-rollout\n</code></pre>"},{"location":"grpc/","title":"gRPC","text":"<p>Utilizza protocol buffer che per la serializzazione/deserializzazione \u00e8 molto pi\u00f9 performante rispetto ad un JSON visto che sono byte scambiati. Tra gli svantaggi si pu\u00f2 notare che il debugging, ad esempio, \u00e8 pi\u00f9 ostico perch\u00e8 si necessita di avere un qualcosa che trasforma quei dati in formato leggibili (altrimenti rimangono byte).</p>"},{"location":"grpc/#app-grpc-rilasciata-come-helm-chart-in-argocd","title":"App gRPC rilasciata come Helm Chart in ArgoCD","text":""},{"location":"grpc/#1-creazione-namespace-grpc-demo","title":"1. Creazione namespace grpc-demo","text":"<p>Aggiungere annotazione:</p> <pre><code>labels: \n  argocd.argoproj.io/managed-by: openshift-gitops\n</code></pre>"},{"location":"grpc/#2-rilascio-applicazione-quarkus","title":"2. Rilascio applicazione Quarkus","text":"<p>Rilasciamo una applicazione Quarkus che stabilisce una comunicazione client-server con protocollo grpc per verificare la mancanza di bilanciamento (multiplexing)</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: grpc-demo\n  namespace: openshift-gitops\nspec:\n  destination:\n    namespace: grpc-demo\n    server: https://kubernetes.default.svc\n  source:\n    path: grpc/helm-charts/grpc-demo-services\n    repoURL: https://github.com/nictore/ocp-demo.git\n    targetRevision: HEAD\n    helm:\n      releaseName: grpc-demo-services\n      valueFiles:\n      - values.yaml\n  sources: []\n  project: default\n  syncPolicy:\n    syncOptions:\n      - CreateNamespace=true\n</code></pre>"},{"location":"grpc/#3-test-di-comunicazione","title":"3. Test di comunicazione","text":"<p>Accedere al client grpc ed eseguire:</p> <pre><code>oc -n test exec deploy/grpc-client -- curl http://localhost:8080/hello/grpc\n</code></pre> <p>Verificare i log lato server, solo una istanza ha ricevuto i messaggi</p>"},{"location":"grpc/#4-osservazioni","title":"4. Osservazioni","text":"<p>Perch\u00e9 il traffico gRPC non \u00e8 bilanciato correttamente in Kubernetes?</p> <p>Il motivo principale per cui \u00e8 difficile bilanciare il traffico gRPC \u00e8 che spesso... si pensa che gRPC sia come HTTP ed \u00e8 qui che inizia il problema mentre HTTP crea e chiude connessioni per richiesta, gRPC opera su protocollo HTTP2 che funziona su una connessione TCP di lunga durata rendendo pi\u00f9 difficile il bilanciamento poich\u00e9 pi\u00f9 richieste passano attraverso la stessa connessione grazie alla funzionalit\u00e0 di multiplexing. Tuttavia, ci sono altri errori comuni:</p> <ul> <li>Configurazione errata del client gRPC</li> <li>Configurazione errata del service Kubernetes</li> </ul>"},{"location":"grpc/#app-grpc-con-istio","title":"App gRPC con Istio","text":"<p>Rilasciamo la stessa applicazione Quarkus client-server con istio per verificare gestione delle connessioni multiple grazie agli envoy</p>"},{"location":"grpc/#1-creazione-namespace-grpc-demo-istio","title":"1. Creazione namespace grpc-demo-istio","text":"<p>Aggiungere annotazione:</p> <pre><code>labels: \n  argocd.argoproj.io/managed-by: openshift-gitops\n</code></pre>"},{"location":"grpc/#2-aggiornare-servicemeshmemberroll","title":"2. Aggiornare ServiceMeshMemberRoll","text":"<pre><code>apiVersion: maistra.io/v1\nkind: ServiceMeshMemberRoll\nmetadata:\n  name: default\n  namespace: istio-system\nspec:\n  members:\n    - bookinfo\n    - grpc-demo-istio\n</code></pre>"},{"location":"grpc/#3-rilascio-app-grpc-con-istio","title":"3. Rilascio app gRPC con Istio","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: grpc-demo-istio\n  namespace: openshift-gitops\nspec:\n  destination:\n    namespace: grpc-demo-istio\n    server: https://kubernetes.default.svc\n  source:\n    path: grpc/helm-charts/grpc-demo-services-istio\n    repoURL: https://github.com/nictore/ocp-demo.git\n    targetRevision: HEAD\n    helm:\n      releaseName: grpc-demo-services-istio\n      valueFiles:\n      - values.yaml\n  sources: []\n  project: default\n  syncPolicy:\n    syncOptions:\n      - CreateNamespace=true\n</code></pre>"},{"location":"grpc/#4-test-di-comunicazione","title":"4. Test di comunicazione","text":"<p>Accedere al client grpc ed eseguire:</p> <pre><code>oc -n test exec deploy/grpc-client -- curl http://localhost:8080/hello/grpc\n</code></pre> <p>Verifichiamo i log lato server, traffico bilanciato correttamente. I proxy envoy si occupano loro di stabilire una connessione per ciascuno pod e di bilanciare le richieste.</p>"},{"location":"grpc/#accesso-grpc-service-via-ingress-controller","title":"Accesso gRPC service via ingress controller","text":"<p>Openshift utilizza HAProxy come ingress controller, HTTP2 non \u00e8 abilitato come impostazione predefinita. Pu\u00f2 essere abilitato come segue:</p> <pre><code>oc annotate ingresses.config/cluster ingress.operator.openshift.io/default-enable-http2=true\n</code></pre>"},{"location":"grpc/#grpc-senza-istio","title":"gRPC senza Istio?","text":"<p>Il motivo principale per cui \u00e8 difficile bilanciare il traffico gRPC \u00e8 che le persone vedono gRPC come HTTP ed \u00e8 qui che inizia il problema, sono diversi, mentre HTTP apre e chiude le connessioni per richiesta, gRPC opera su un protocollo HTTP2 che funziona su una connessione TCP di lunga durata che rende pi\u00f9 difficile il bilanciamento poich\u00e9 pi\u00f9 richieste passano attraverso la stessa connessione grazie alla funzione multiplex.</p> <p>Senza una service mesh \u00e8 necessario implementare soluzioni alternative per gestire efficacemente il bilanciamento del carico del traffico gRPC in Kubernetes. Queste soluzioni possono includere la configurazione diretta dei client per gestire pi\u00f9 connessioni server.</p>"},{"location":"grpc/#configurazione-client-grpc","title":"Configurazione client gRPC","text":"<p>Il client gRPC predefinito offre la possibilit\u00e0 di connettersi con un semplice record IP/DNS che crea una sola connessione con il servizio di destinazione. Ecco perch\u00e9 \u00e8 necessario effettuare una configurazione diversa. Esempio in go:</p> <p>Impostazione di default:</p> <pre><code>func main(){ \n  conn, err := grpc.Dial(\"my-domain:50051\", grpc.WithInsecure()) \n  if err != nil { \n    log.Fatalf(\"errore di connessione con il server gRPC: %v\", err) \n  }\n  ...\n</code></pre> <p>Impostazione consigliata:</p> <pre><code>func main(){ \n  addr := fmt.Sprintf(\"%s:///%s\", \"dns\", \" my-domain :50051\") \n  conn, err := grpc.Dial(addr, grpc.WithInsecure(),grpc.WithBalancerName(roundrobin.Name)) \n  if err != nil { \n    log.Fatalf(\"connessione non riuscita: %v\", err) \n  } \n  ...\n</code></pre> <p>In questo modo nel caso in cui il nostro client si connetta a pi\u00f9 server, ora il nostro client gRPC \u00e8 in grado di bilanciare le richieste in base all'algoritmo di bilanciamento scelto.</p> <p>N.B. Manca ancora una cosa, assicurarsi che la risoluzione DNS funzioni come ci aspettiamo.</p>"},{"location":"grpc/#configurazione-headless-service","title":"Configurazione headless service","text":"<p>La creazione di un service in Kubernetes \u00e8 piuttosto semplice, basta definire il nome, le porte ed il selector, in modo che il service possa raggruppare i pod dinamicamente e bilanciare automaticamente la richiesta:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: my-app\n  ports:\n    - name: grpc\n      protocol: TCP\n      port: 50051\n      targetPort: 50051\n</code></pre> <p>Qual \u00e8 il problema? Semplicemente che il service Kubernetes crea un record DNS che collega un solo IP, il clusterIP, quindi quando si fa qualcosa come nslookup my-service.{namespace}.svc.cluster.local ci\u00f2 che viene restituito \u00e8 un singolo IP, il che ci riporterebbe al problema iniziale:</p> <p></p> <p>Risolviamo il problema utilizzando un servizio headless:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n clusterIP: None **LA SOLUZIONE!**\n selector:\n    app: my-app\n  ports:\n    - name: grpc\n      protocol: TCP\n      port: 50051\n      targetPort: 50051\n</code></pre> <p>Impostando il campo clusterIP in una specifica di servizio su None, il service diventa headless, poich\u00e9 Kubernetes non gli assegner\u00e0 un IP cluster tramite il quale i client potrebbero connettersi ai pod che lo supportano. Un nslookup cos\u00ec appare un po' diverso, restituisce gli indirizzi IP dei pod associati dando al client gRPC una giusta visibilit\u00e0 del numero di server che devono essere raggiunti.</p> <p></p>"},{"location":"grpc/#considerazioni","title":"Considerazioni","text":"<p>Sebbene la configurazioni appena vista funzioni ci sono delle considerazioni da fare:</p> <ul> <li>Se il client gRPC deve connettersi a molti server, avere la gestione nell'applicazione aumenter\u00e0 la complessit\u00e0 ed il consumo di risorse nel tentativo di mantenere molte connessioni aperte.</li> <li>Con un service mesh tutta questa configurazione \u00e8 trasparente ed inoltre indipendente dal linguaggio.</li> </ul>"},{"location":"security/","title":"Security","text":"<p>Service Mesh consente di crittografare tutto il traffico senza richiedere modifiche al codice, senza complicati aggiornamenti di rete e senza installare/utilizzare strumenti esterni.</p> <p>Per impostazione predefinita, mTLS in OpenShift Service Mesh viene abilitato e impostato Permissive Mode, i sidecar in Service Mesh accettano sia il traffico in plain text sia le connessioni crittografate tramite mTLS.</p> <p>Abilitando mTLS nella mesh a livello di Control Plane (ServiceMeshControlPlane) \u00e8 possibile proteggere i namespace dichiarati nella mesh. Per personalizzare le connessioni di crittografia del traffico i namespace devono essere configurati con le risorse PeerAuthentication e DestinationRule.</p> <p></p> <p>La CA di Istio genera automaticamente certificati per supportare le connessioni mTLS e li inietta nei pod dell'applicazione. In questo caso, l'utilizzo di mTLS comporta un ulteriore vantaggio poich\u00e9 consente agli amministratori di creare regole di controllo degli accessi basate sui ruoli (RBAC) nel cluster OpenShift per specificare quale client pu\u00f2 connettersi a quali servizi.</p>"},{"location":"security/#abilitare-mtls","title":"Abilitare mTLS","text":"<pre><code>apiVersion: maistra.io/v2\nkind: ServiceMeshControlPlane\nspec:\n  security:\n    dataPlane:\n      mtls: true\n</code></pre>"},{"location":"security/#verifica-mtls-status","title":"Verifica mTLS status","text":"<p>La console Kiali offre diversi modi per verificare se le applicazioni, i servizi e i carichi di lavoro hanno la crittografia mTLS abilitata o meno.</p> <p></p> <p>Sul lato destro del masthead, Kiali mostra un'icona a forma di lucchetto quando la mesh ha abilitato rigorosamente mTLS per l'intera service mesh. Ci\u00f2 significa che tutte le comunicazioni nella mesh utilizzano mTLS.</p> <p></p> <p>Kiali visualizza un'icona a forma di lucchetto vuoto quando la mesh \u00e8 configurata in PERMISSIVEmodalit\u00e0 o si verifica un errore nella configurazione mTLS dell'intera mesh.</p>"},{"location":"security/#configurazione-tls-gateway","title":"Configurazione TLS Gateway","text":"<p>Per esporre un gateway in https \u00e8 sufficiente aggiungere all'interno della sua configurazione la sezione TLS con riferimento alla secret contenente certificato e chiave:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: Gateway\nmetadata:\n  name: bookinfo-gateway\n  namespace: bookinfo\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n    - hosts:\n        - bookinfo.apps.lab.dpastore.uk\n      port:\n        name: https\n        number: 443\n        protocol: HTTPS\n      tls:\n        credentialName: bookinfo-credential\n        mode: SIMPLE\n</code></pre>"},{"location":"security/#controllo-outbound","title":"Controllo outBound","text":"<p>Istio ha un'opzione che consente di configurare i sidecar per abilitare o bloccare connessioni verso servizi esterni, ovvero quei servizi che non sono definiti nel registro della mesh. Di default questa opzione \u00e8 impostata su ALLOW_ANY, il proxy Istio infatti lascia passare le chiamate a servizi sconosciuti. Se l'opzione \u00e8 impostata su REGISTRY_ONLY, il proxy Istio blocca qualsiasi host senza un servizio HTTP o una voce di servizio definita all'interno della mesh.</p> <p>Per il passaggio alla modalit\u00e0 REGISTRY_ONLY aggiungere in ServiceMeshControlPlane:</p> <pre><code>spec:\n   proxy:\n     networking:\n       trafficControl:\n         outbound:\n           policy: REGISTRY_ONLY\n</code></pre> <p>Definire un ServiceEntry per abilitare l'outbound verso un servizio esterno:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: ServiceEntry\nmetadata:\n  name: ext-httpbin\n  namespace: bookinfo\nspec:\n  hosts:\n    - httpbin.org\n  location: MESH_EXTERNAL\n  ports:\n    - name: https\n      number: 443\n      protocol: HTTPS\n  resolution: DNS\n</code></pre>"},{"location":"servicemesh/","title":"Service Mesh Demo","text":""},{"location":"servicemesh/#1-requisiti","title":"1. Requisiti","text":""},{"location":"servicemesh/#11-setup-operators","title":"1.1 Setup Operators","text":"<pre><code>1. OpenShift Elasticsearch Operator\n2. Red Hat OpenShift distributed tracing platform\n3. Kiali Operator\n4. Red Hat OpenShift Service Mesh\n</code></pre>"},{"location":"servicemesh/#12-definizione-servicemeshcontrolplane","title":"1.2 Definizione ServiceMeshControlPlane","text":"<pre><code>apiVersion: maistra.io/v2\nkind: ServiceMeshControlPlane\nmetadata:\n  name: basic\n  namespace: istio-system\nspec:\n  addons:\n    grafana:\n      enabled: true\n    jaeger:\n      install:\n        storage:\n          type: Memory\n    kiali:\n      enabled: true\n    prometheus:\n      enabled: true\n  gateways:\n    openshiftRoute:\n      enabled: true\n  mode: MultiTenant\n  policy:\n    type: Istiod\n  profiles:\n    - default\n  telemetry:\n    type: Istiod\n  tracing:\n    sampling: 10000\n    type: Jaeger\n  version: v2.6\n</code></pre>"},{"location":"servicemesh/#2-aggiunta-di-servizi-in-service-mesh","title":"2. Aggiunta di servizi in Service Mesh","text":""},{"location":"servicemesh/#21-definizione-servicemeshmemberroll","title":"2.1 Definizione ServiceMeshMemberRoll","text":"<p>Questo oggetto fornisce agli amministratori di OpenShift Service Mesh un modo per delegare le autorizzazioni e per aggiungere progetti a una mesh.</p> <pre><code>apiVersion: maistra.io/v1\nkind: ServiceMeshMemberRoll\nmetadata:\n  name: default\n  namespace: istio-system\nspec:\n  members:\n    - bookinfo\n</code></pre> <p>La Service Mesh definisce anche le network policy nella control plane della Service Mesh e nei namespace partecipanti, regolando il traffico all'interno della mesh.</p> <pre><code>oc get netpol -n bookinfo\n\nistio-expose-route-basic\nistio-mesh-basic\n</code></pre>"},{"location":"servicemesh/#3-deploy-bookinfo","title":"3. Deploy Bookinfo","text":"<p>L'applicazione Bookinfo visualizza informazioni simili ad un negozio di libri online. L'applicazione mostra una pagina che descrive il libro, i suoi dettagli (ISBN, numero di pagine e altre informazioni) e le recensioni ricevute.</p> <p>L'applicazione Bookinfo \u00e8 composta da questi microservizi:</p> <p>Il microservizio productpage chiama i microservizi details e reviews per popolare la pagina. Il microservizio details contiene informazioni sui libri. Il microservizio reviews contiene le recensioni dei librie e chiama il microservizio dei ratings. Il microservizio dei ratings contiene le informazioni sulle classifiche dei libri che accompagnano le recensioni.</p> <p>Esistono tre versioni del microservizio reviews:</p> <ul> <li>La versione v1 non chiama il servizio di ratings.</li> <li>La versione v2 chiama il Servizio reviews e visualizza ogni valutazione con stelle nere.</li> <li>La versione v3 chiama il Servizio reviews e visualizza ogni valutazione con stelle rosse.</li> </ul> <p>-&gt; bookinfo.yaml</p>"},{"location":"servicemesh/#4-sidecar-injection","title":"4. Sidecar Injection","text":"<p>Annotations nei deployment per abilitare l'injection del proxy istio</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n    [...]\nspec:\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'true'\n</code></pre> <p>E' possibile sfruttare l'injection automatica dei sidecar configurando una label direttamente sul namespace: </p> <pre><code>$ oc label namespace &lt;nome_namespace&gt; istio-injection=enabled\n</code></pre>"},{"location":"servicemesh/#5-versioning-del-deployment","title":"5. Versioning del deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n    [...]\nspec:\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v1\n</code></pre>"},{"location":"servicemesh/#6-definizione-ingressgateway","title":"6. Definizione IngressGateway","text":"<p>Una risorsa gateway rappresenta un bilanciatore di carico che opera ai margini della mesh, gestendo le connessioni HTTP/TCP in entrata e in uscita. La sua specifica descrive:</p> <ul> <li>un set di porte che devono essere esposte</li> <li>il tipo di protocollo da utilizzare</li> <li>la configurazione SNI per il bilanciatore di carico e altro ancora.</li> </ul> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: Gateway\nmetadata:\n  name: bookinfo-gateway\nspec:\n  selector:\n    istio: ingressgateway # use istio default controller\n  servers:\n  - port:\n      number: 8080\n      name: http\n      protocol: HTTP\n    hosts: \n    - \"*\"\n</code></pre> <p>A differenza di una Ingress o Rotta standard, non include alcuna configurazione di routing del traffico. Il routing del traffico \u00e8 invece configurato utilizzando l'oggetto VirtualService.</p>"},{"location":"servicemesh/#7-definizione-virtualservices","title":"7. Definizione VirtualServices","text":"<p>Per specificare il routing e per far funzionare il gateway come previsto, bisogna anche associare il gateway a un virtualService:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: bookinfo\nspec:\n  hosts:\n  - \"*\"\n  gateways:\n  - bookinfo-gateway\n  http:\n  - match:\n    - uri:\n        exact: /productpage\n    - uri:\n        prefix: /static\n    - uri:\n        exact: /login\n    - uri:\n        exact: /logout\n    - uri:\n        prefix: /api/v1/products\n    route:\n    - destination:\n        host: productpage\n        port:\n          number: 9080\n</code></pre>"},{"location":"servicemesh/#8-gestione-del-traffico","title":"8. Gestione del traffico","text":"<p>Per il microservizio reviews definiamo un oggetto DestinationRule per identificare i subset in base alla versione del deployment, configura quindi tre diversi sottoinsiemi:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: reviews\n  namespace: bookinfo\nspec:\n  host: reviews\n  subsets:\n    - labels:\n        version: v1\n      name: v1\n    - labels:\n        version: v2\n      name: v2\n    - labels:\n        version: v3\n      name: v3\n  trafficPolicy:\n    loadBalancer:\n      simple: RANDOM\n</code></pre>"},{"location":"servicemesh/#scenario-1-routing","title":"Scenario 1 (Routing)","text":"<p>Veicoliamo tutto il traffico solo per la versione v1 di review e poi solo per v2</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  hosts:\n  - reviews\n  http:\n  - route:\n    - destination:\n        host: reviews\n        subset: v1   #v2\n</code></pre>"},{"location":"servicemesh/#scenario-2-shifting","title":"Scenario 2 (Shifting)","text":"<p>Veicoliamo una percentuale di traffico sulle 2 istanze v1 e v2</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  hosts:\n    - reviews\n  http:\n  - route:\n    - destination:\n        host: reviews\n        subset: v1\n      weight: 80\n    - destination:\n        host: reviews\n        subset: v2\n      weight: 20\n</code></pre>"},{"location":"servicemesh/#scenario-3-http-header","title":"Scenario 3 (Http header)","text":"<p>Set header http, veicola traffico solo su v2 solo se corrisponde un determinato utente</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  hosts:\n  - reviews\n  http:\n  - match:\n    - headers:\n        end-user:\n          exact: jason\n    route:\n    - destination:\n        host: reviews\n        subset: v2\n  - route:\n    - destination:\n        host: reviews\n        subset: v3\n</code></pre>"},{"location":"servicemesh/#scenario-4-fault-injection","title":"Scenario 4 (Fault Injection)","text":"<p>Fault injection microservizio details e osservere jaeger</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: details\nspec:\n  host: details\n  subsets:\n  - name: v1\n    labels:\n      version: v1\n---\napiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: details\nspec:\n  hosts:\n  - details\n  http:\n  - fault:\n      abort:\n        httpStatus: 555\n        percentage:\n          value: 100\n    route:\n    - destination:\n        host: details\n        subset: v1\n</code></pre>"},{"location":"servicemesh/#scenario-5-delay","title":"Scenario 5 (Delay)","text":"<p>Delay</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: details\nspec:\n  hosts:\n  - details\n  http:\n  - fault:\n      delay:\n        fixedDelay: 7s\n        percentage:\n          value: 100\n    route:\n    - destination:\n        host: details\n        subset: v1\n</code></pre>"},{"location":"servicemesh/#scenario-6-mirroring","title":"Scenario 6 (Mirroring)","text":"<p>Mirroring del traffico osservare con grafana Il mirroring invia una copia del traffico live a un servizio mirrorato.</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  hosts:\n    - reviews\n  http:\n  - route:\n    - destination:\n        host: reviews\n        subset: v1\n      weight: 100\n    mirror:\n        host: reviews\n        subset: v2\n    mirrorPercentage:\n    value: 100.0\n</code></pre>"},{"location":"servicemesh/#scenario-7-circuit-breaking","title":"Scenario 7 (Circuit breaking)","text":"<p>Il circuit breaking \u00e8 un pattern importante per la creazione di applicazioni microservice resilienti. Il circuit breaking consente di scrivere applicazioni che limitano l'impatto di guasti, picchi di latenza e altri effetti indesiderati delle peculiarit\u00e0 della rete.</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: details\nspec:\n  host: details\n  subsets:\n  - name: v1\n    labels:\n      version: v1\n  trafficPolicy:\n    connectionPool:\n      tcp:\n        maxConnections: 1\n      http:\n        http1MaxPendingRequests: 1\n        maxRequestsPerConnection: 1\n    outlierDetection:\n      consecutive5xxErrors: 1\n      interval: 1s\n      baseEjectionTime: 3m\n      maxEjectionPercent: 100\n</code></pre> <p>Queste regole indicano che se si supera pi\u00f9 di una connessione e contemporanea, dovrebbero verificarsi alcuni errori quando istio-proxy tenta di aprire ulteriori richieste e connessioni.</p> <pre><code>maxConnections: 1 \nhttp1MaxPendingRequests: 1\n</code></pre>"}]}